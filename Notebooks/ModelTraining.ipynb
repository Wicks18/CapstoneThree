{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eliwi\\anaconda3\\envs\\torchnlp\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, string, re, zipfile\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file exists\n",
    "if not os.path.exists('..\\\\Data\\\\final_train.csv'):\n",
    "    # Go back one directory\n",
    "    os.chdir('..\\\\Data')\n",
    "\n",
    "    # Download the dataset from Kaggle\n",
    "    !kaggle datasets download -d jdragonxherrera/augmented-data-for-llm-detect-ai-generated-text\n",
    "\n",
    "    zip_path = \"augmented-data-for-llm-detect-ai-generated-text.zip\"  # replace with the path to your zip file\n",
    "    extract_path = \".\"  # replace with the path where you want to extract the files\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    \n",
    "    os.chdir('..\\\\Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We should keep the Electoral College for a num...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>More and more money is spent on building theat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Limiting car usage can actually be effective b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Mrs. Smith,\\n\\nI am writing to you today ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Principal,\\n\\nAfter school or during scho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86582</th>\n",
       "      <td>Dear Principal: I think we should have cell ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86583</th>\n",
       "      <td>Dear Teacher_NAME\\n\\nI think that if you try t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86584</th>\n",
       "      <td>Venus is sometimes called the \"meaning Star.\" ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86585</th>\n",
       "      <td>The Seagoing Cowboy Bros\\n\\nDo you like going ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86586</th>\n",
       "      <td>In Emerson's Words, \"In the World, be yoursel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433564 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      We should keep the Electoral College for a num...      0\n",
       "1      More and more money is spent on building theat...      1\n",
       "2      Limiting car usage can actually be effective b...      0\n",
       "3      Dear Mrs. Smith,\\n\\nI am writing to you today ...      1\n",
       "4      Dear Principal,\\n\\nAfter school or during scho...      0\n",
       "...                                                  ...    ...\n",
       "86582  Dear Principal: I think we should have cell ph...      0\n",
       "86583  Dear Teacher_NAME\\n\\nI think that if you try t...      0\n",
       "86584  Venus is sometimes called the \"meaning Star.\" ...      0\n",
       "86585  The Seagoing Cowboy Bros\\n\\nDo you like going ...      0\n",
       "86586   In Emerson's Words, \"In the World, be yoursel...      1\n",
       "\n",
       "[433564 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augmented data for LLM - Detect AI Generated Text by jdragonxherrera on Kaggle\n",
    "df_train = pd.read_csv('../Data/final_train.csv')\n",
    "df_test = pd.read_csv('../Data/final_test.csv')\n",
    "df = pd.concat([df_train, df_test])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "embedding_dim = 64\n",
    "sequence_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eliwi\\anaconda3\\envs\\torchnlp\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\eliwi\\anaconda3\\envs\\torchnlp\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shuffled_df = df.sample(frac=1, random_state=1818)\n",
    "# Remove 80% of the data\n",
    "num_samples_to_remove = int(0.8 * len(shuffled_df))\n",
    "remaining_df = shuffled_df.iloc[num_samples_to_remove:]\n",
    "\n",
    "\n",
    "train_df, remaining_df = train_test_split(remaining_df, train_size=0.8, random_state=1818)\n",
    "val_df, test_df = train_test_split(remaining_df, train_size=0.5, random_state=1818)\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((df['text'].values))\n",
    "ds = ds.batch(512)\n",
    "vectorize_layer.adapt(ds)\n",
    "\n",
    "# Vectorize the data\n",
    "\n",
    "train_text = np.array(vectorize_layer(train_df['text']))\n",
    "val_text = np.array(vectorize_layer(val_df['text']))\n",
    "test_text = np.array(vectorize_layer(test_df['text']))\n",
    "\n",
    "train_labels = np.array(train_df['label'])\n",
    "val_labels = np.array(val_df['label'])\n",
    "test_labels = np.array(test_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial model testing resulted in the following results, tested on data from the augmented-llm-data and on the data provided by the competition.\n",
    "\n",
    "- Embedding, Conv1D, and Dense dim of 128\n",
    "    - trained on 3 epochs had a test accuracy of 0.9905 and 0.9811 and took 2m 42.4s\n",
    "    - trained on 6 epochs had a test accuracy of 0.9905 and 0.9601 and took 5m 17.6s\n",
    "- Embedding, Conv1D, and Dense dim of 64\n",
    "    - trained on 3 epochs had a test accuracy of 0.9983 and 0.9800 and took 1m 10.1s\n",
    "    - trained on 6 epochs had a test accuracy of 0.9908 and 0.9586 and took 2m 19.3s\n",
    "\n",
    "Extra epochs resulted in lower accuracy on the competition test set. For that reason, 3 epochs were chosen.\n",
    "\n",
    "As the competition also has a 'Training Efficiency' portion, a low train time was preferred and a dim of 64 was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eliwi\\anaconda3\\envs\\torchnlp\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\eliwi\\anaconda3\\envs\\torchnlp\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2168/2168 [==============================] - 24s 11ms/step - loss: 0.0868 - accuracy: 0.9658 - val_loss: 0.0281 - val_accuracy: 0.9922\n",
      "Epoch 2/3\n",
      "2168/2168 [==============================] - 23s 11ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.0185 - val_accuracy: 0.9941\n",
      "Epoch 3/3\n",
      "2168/2168 [==============================] - 22s 10ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0175 - val_accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d9c36f73d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A integer input for vocab indices.\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "x = layers.Embedding(max_features, 64)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(64, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(64, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# Add a vanilla hidden layer:\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "# Fit the model using the train and val datasets.\n",
    "model.fit(train_text, train_labels, validation_data=(val_text, val_labels), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take generated essays and student essays provided by the competition\n",
    "combined_data = pd.read_csv('../Data/Detect AI Generated Text/combined_essays.csv')\n",
    "\n",
    "# Drop the id, prompt_id, text_len, and model columns\n",
    "combined_data = combined_data.drop(['id', 'prompt_id', 'text_len', 'model'], axis=1)\n",
    "\n",
    "# Rename the 'generated' column to 'label'\n",
    "combined_data = combined_data.rename(columns={'generated': 'label'})\n",
    "\n",
    "# Convert the label column to a boolean and the text column to a string\n",
    "combined_data['label'] = combined_data['label'].astype(bool)\n",
    "combined_data['text'] = combined_data['text'].astype(str)\n",
    "\n",
    "# Create a test set from the combined data for the keras model\n",
    "cd_text = np.array(vectorize_layer(combined_data['text']))\n",
    "cd_labels = np.array(combined_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "271/271 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9933\n",
      "test loss, test acc: [0.0267432052642107, 0.9933118224143982]\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9800\n",
      "test loss, test acc: [0.06940004229545593, 0.9800435304641724]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_text, test_labels)\n",
    "print(\"test loss, test acc:\", results)\n",
    "results = model.evaluate(cd_text, cd_labels, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition allowed for the best of 3 notebooks to be used.\n",
    "\n",
    "Initial:\n",
    "- Embedding, Conv1D, and Dense dim of 64\n",
    "    - trained on 20% of the augmented-llm-data had a test accuracy of 0.9933 and 0.9800 and took 1m 10.1s\n",
    "\n",
    "Best:\n",
    "- Embedding, Conv1D, and Dense dim of 64\n",
    "    - trained on 60% of the augmented-llm-data had a test accuracy of 0.9976 and 0.9851 and took 3m 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data for the Perceptron\n",
    "vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "vectorizer.fit(df['text'])\n",
    "\n",
    "# Vectorize the train and test data\n",
    "train_vectors = vectorizer.transform(train_df['text'])\n",
    "test_vectors = vectorizer.transform(test_df['text'])\n",
    "\n",
    "# Create additonal test set from the combined data for the perceptron\n",
    "cd_vectors = vectorizer.transform(combined_data['text'])\n",
    "cd_labels = combined_data['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5508\n",
      "           1       0.99      0.99      0.99      3164\n",
      "\n",
      "    accuracy                           0.99      8672\n",
      "   macro avg       0.99      0.99      0.99      8672\n",
      "weighted avg       0.99      0.99      0.99      8672\n",
      "\n",
      "[[5486   22]\n",
      " [  45 3119]]\n"
     ]
    }
   ],
   "source": [
    "perceptron_model = Perceptron(max_iter=1000)\n",
    "perceptron_model.fit(train_vectors, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = perceptron_model.predict(test_vectors)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# classification report\n",
    "print(classification_report(test_labels, predictions))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2710/2710 [==============================] - 4s 2ms/step\n",
      "[1 1 1 0 0] [1 1 1 0 0]\n",
      "Accuracy: 0.99\n",
      "Binary Accuracy: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     55334\n",
      "           1       0.99      0.99      0.99     31379\n",
      "\n",
      "    accuracy                           0.99     86713\n",
      "   macro avg       0.99      0.99      0.99     86713\n",
      "weighted avg       0.99      0.99      0.99     86713\n",
      "\n",
      "[[55144   190]\n",
      " [  349 31030]]\n"
     ]
    }
   ],
   "source": [
    "class Classifier():\n",
    "    def __init__(self, tensor_model, perceptron_model):\n",
    "        self.tensor_model = tensor_model\n",
    "        self.perceptron_model = perceptron_model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # No training needed for TensorFlow model in this case\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Convert the dataset to the expected format\n",
    "        tensor_X = np.array(vectorize_layer(X))\n",
    "        tensor_predictions = self.tensor_model.predict(tensor_X)\n",
    "        tensor_predictions = np.array(tensor_predictions).flatten()\n",
    "        perceptron_X = vectorizer.transform(X)\n",
    "        perceptron_predictions = self.perceptron_model.predict(perceptron_X)\n",
    "        # Turn the perceptron predictions into a 1D array of floats\n",
    "        perceptron_predictions = np.array(perceptron_predictions).flatten().astype(float)\n",
    "        # Average the predictions along the array axis\n",
    "        predictions = np.mean([tensor_predictions, perceptron_predictions], axis=0)\n",
    "        # Convert the predictions to binary\n",
    "        predictions = np.where(predictions > 0.5, 1, 0)\n",
    "        return predictions\n",
    "    \n",
    "classifier = Classifier(tensor_model=model, perceptron_model=perceptron_model)\n",
    "train_df, test_df = train_test_split(shuffled_df, train_size=0.8, random_state=42)\n",
    "\n",
    "train_labels2 = train_df['label'].to_numpy()\n",
    "test_labels2 = test_df['label'].to_numpy()\n",
    "# Get predictions from each model\n",
    "predictions = classifier.predict(test_df['text'])  # Adjust according to your TensorFlow model\n",
    "\n",
    "print(predictions[:5], test_labels2[:5])\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(test_labels2, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(test_labels2, predictions)\n",
    "print(f\"Binary Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# classification report\n",
    "print(classification_report(test_labels2, predictions))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_labels2, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the Keras and Perceptron models into a classifier results in an accuracy of 99.378%.\n",
    "\n",
    "My notebook tested on 46% of the competition's final test data achieved an accuracy of 85.67% and placed 3053 out of 4359.\n",
    "\n",
    "Final results on 54% of test data were 74.25% and placed 2882 out of 4359."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
