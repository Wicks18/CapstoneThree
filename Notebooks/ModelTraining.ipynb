{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\eliwi\\anaconda3\\envs\\torchnlp\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented data for LLM - Detect AI Generated Text by jdragonxherrera on Kaggle\n",
    "df = pd.read_csv('../Data/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "embedding_dim = 64\n",
    "sequence_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = df.sample(frac=1, random_state=1818)\n",
    "# Remove 80% of the data\n",
    "num_samples_to_remove = int(0.8 * len(shuffled_df))\n",
    "remaining_df = shuffled_df.iloc[num_samples_to_remove:]\n",
    "\n",
    "\n",
    "train_df, remaining_df = train_test_split(remaining_df, train_size=0.8, random_state=1818)\n",
    "val_df, test_df = train_test_split(remaining_df, train_size=0.5, random_state=1818)\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((df['text'].values))\n",
    "ds = ds.batch(512)\n",
    "vectorize_layer.adapt(ds)\n",
    "\n",
    "# Vectorize the data\n",
    "\n",
    "train_text = np.array(vectorize_layer(train_df['text']))\n",
    "val_text = np.array(vectorize_layer(val_df['text']))\n",
    "test_text = np.array(vectorize_layer(test_df['text']))\n",
    "\n",
    "train_labels = np.array(train_df['label'])\n",
    "val_labels = np.array(val_df['label'])\n",
    "test_labels = np.array(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2168/2168 [==============================] - 24s 11ms/step - loss: 0.0919 - accuracy: 0.9626 - val_loss: 0.0238 - val_accuracy: 0.9930\n",
      "Epoch 2/3\n",
      "2168/2168 [==============================] - 23s 11ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.0191 - val_accuracy: 0.9946\n",
      "Epoch 3/3\n",
      "2168/2168 [==============================] - 23s 11ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0175 - val_accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x242e69f0b90>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A integer input for vocab indices.\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(64, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(64, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# Add a vanilla hidden layer:\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "# Fit the model using the train and val datasets.\n",
    "model.fit(train_text, train_labels, validation_data=(val_text, val_labels), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../Data/Detect AI Generated Text/combined_essays.csv')\n",
    "# Drop the id, prompt_id, text_len, and model columns\n",
    "combined_data = combined_data.drop(['id', 'prompt_id', 'text_len', 'model'], axis=1)\n",
    "# Rename the 'generated' column to 'label'\n",
    "combined_data = combined_data.rename(columns={'generated': 'label'})\n",
    "# Convert the label column to a boolean and the text column to a string\n",
    "combined_data['label'] = combined_data['label'].astype(bool)\n",
    "combined_data['text'] = combined_data['text'].astype(str)\n",
    "\n",
    "cd_text = np.array(vectorize_layer(combined_data['text']))\n",
    "cd_labels = np.array(combined_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "271/271 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9932\n",
      "test loss, test acc: [0.0230079498142004, 0.9931964874267578]\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9775\n",
      "test loss, test acc: [0.09002448618412018, 0.9775036573410034]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_text, test_labels)\n",
    "print(\"test loss, test acc:\", results)\n",
    "results = model.evaluate(cd_text, cd_labels, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model 2 accuracy was 0.9905/0.9811 & 0.9905/0.9601\n",
    "Model 3 epoch 3 accuracy was 0.9818/0.9677 & 0.9818/0.9968\n",
    "Model 3 epoch 6 accuracy was 0.9908/0.9586 \n",
    "Model 3 epoch 3 0.6 accuracy was 0.9905/0.9811 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "vectorizer.fit(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.transform(train_df['text'])\n",
    "test_vectors = vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cd_vectors = vectorizer.transform(combined_data['text'])\n",
    "cd_labels = combined_data['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5508\n",
      "           1       0.99      0.99      0.99      3164\n",
      "\n",
      "    accuracy                           0.99      8672\n",
      "   macro avg       0.99      0.99      0.99      8672\n",
      "weighted avg       0.99      0.99      0.99      8672\n",
      "\n",
      "[[5486   22]\n",
      " [  45 3119]]\n"
     ]
    }
   ],
   "source": [
    "perceptron_model = Perceptron(max_iter=1000)\n",
    "perceptron_model.fit(train_vectors, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = perceptron_model.predict(test_vectors)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# classification report\n",
    "print(classification_report(test_labels, predictions))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2710/2710 [==============================] - 4s 2ms/step\n",
      "[1 1 1 0 0] [1 1 1 0 0]\n",
      "Accuracy: 0.99\n",
      "Binary Accuracy: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     55334\n",
      "           1       0.99      0.99      0.99     31379\n",
      "\n",
      "    accuracy                           0.99     86713\n",
      "   macro avg       0.99      0.99      0.99     86713\n",
      "weighted avg       0.99      0.99      0.99     86713\n",
      "\n",
      "[[55144   190]\n",
      " [  349 31030]]\n"
     ]
    }
   ],
   "source": [
    "class Classifier():\n",
    "    def __init__(self, tensor_model, perceptron_model):\n",
    "        self.tensor_model = tensor_model\n",
    "        self.perceptron_model = perceptron_model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # No training needed for TensorFlow model in this case\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Convert the dataset to the expected format\n",
    "        tensor_X = np.array(vectorize_layer(X))\n",
    "        tensor_predictions = self.tensor_model.predict(tensor_X)\n",
    "        tensor_predictions = np.array(tensor_predictions).flatten()\n",
    "        perceptron_X = vectorizer.transform(X)\n",
    "        perceptron_predictions = self.perceptron_model.predict(perceptron_X)\n",
    "        # Turn the perceptron predictions into a 1D array of floats\n",
    "        perceptron_predictions = np.array(perceptron_predictions).flatten().astype(float)\n",
    "        # Average the predictions along the array axis\n",
    "        predictions = np.mean([tensor_predictions, perceptron_predictions], axis=0)\n",
    "        # Convert the predictions to binary\n",
    "        predictions = np.where(predictions > 0.5, 1, 0)\n",
    "        return predictions\n",
    "    \n",
    "classifier = Classifier(tensor_model=model, perceptron_model=perceptron_model)\n",
    "train_df, test_df = train_test_split(shuffled_df, train_size=0.8, random_state=42)\n",
    "\n",
    "train_labels2 = train_df['label'].to_numpy()\n",
    "test_labels2 = test_df['label'].to_numpy()\n",
    "# Get predictions from each model\n",
    "predictions = classifier.predict(test_df['text'])  # Adjust according to your TensorFlow model\n",
    "\n",
    "print(predictions[:5], test_labels2[:5])\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(test_labels2, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(test_labels2, predictions)\n",
    "print(f\"Binary Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# classification report\n",
    "print(classification_report(test_labels2, predictions))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_labels2, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
